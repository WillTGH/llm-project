{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to V:/llm-\n",
      "[nltk_data]     project/datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpora Gutenberg is Not There\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.normalizers import (Sequence, Lowercase, NFD, StripAccents)\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.decoders import BPEDecoder\n",
    "\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "\n",
    "nltk.download('gutenberg', download_dir='V:/llm-project/datasets')\n",
    "file_path = 'V:/llm-project/datasets/corpora/gutenberg/'\n",
    "try:\n",
    "    find('V:/llm-project/datasets/corpora/gutenberg')\n",
    "    print('Corpora Gutenberg is There')\n",
    "except LookupError:\n",
    "    print('Corpora Gutenberg is Not There')\n",
    "# nltk.download('V:/llm-project/tokenizer/punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000000\n",
    "plays = [\n",
    "    f'{file_path}austen-sense.txt',\n",
    "    f'{file_path}blake-poems.txt',\n",
    "    f'{file_path}austen-persuasion.txt',\n",
    "    f'{file_path}austen-emma.txt',\n",
    "    f'{file_path}bryant-stories.txt',\n",
    "    f'{file_path}burgess-busterbrown.txt',\n",
    "    f'{file_path}bismarck.txt',\n",
    "    f'{file_path}carroll-alice.txt',\n",
    "    f'{file_path}chesterton-ball.txt',\n",
    "    f'{file_path}chesterton-brown.txt',\n",
    "    f'{file_path}chesterton-thursday.txt',\n",
    "    f'{file_path}corpus1.txt',\n",
    "    f'{file_path}corpus2.txt',\n",
    "    f'{file_path}corpus3.txt',\n",
    "    f'{file_path}corpus4.txt',\n",
    "    f'{file_path}corpus5.txt',\n",
    "    f'{file_path}edgeworth-parents.txt',\n",
    "    f'{file_path}melville-moby_dick.txt',\n",
    "    f'{file_path}milton-paradise.txt',\n",
    "    f'{file_path}shakespeare-macbeth.txt',\n",
    "    f'{file_path}shakespeare-hamlet.txt',\n",
    "    f'{file_path}shakespeare-caesar.txt',\n",
    "    f'{file_path}whitman-leaves.txt'\n",
    "    ]\n",
    "text = [\" \".join(s) for ply in plays for s in gutenberg.sents(ply)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160453\n",
      "But , then , if Mrs . Dashwood should live fifteen years we shall be completely taken in .\"\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(text[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens=[\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[PAD]\",\"[MASK]\"]\n",
    "temp_proc = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", special_tokens.index(\"[CLS]\")),\n",
    "        (\"[SEP]\", special_tokens.index(\"[SEP]\")),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.normalizer = Sequence([NFD(),Lowercase(),StripAccents()])\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.decoder = BPEDecoder()\n",
    "tokenizer.post_processor=temp_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BpeTrainer(vocab_size=vocab_size,special_tokens=special_tokens)\n",
    "tokenizer.train_from_iterator(text, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vocab size: 133242\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trained vocab size: {tokenizer.get_vocab_size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"In a random hidden valley surrounded by towering mountains, the ancient village of Eldoria thrived in harmonious isolation. The villagers spoke of magical creatures dwelling in the dense forests, guardians of secrets lost to time. Each spring, a festival of lights transformed the village into a realm of wonder, with lanterns floating like ethereal fireflies against the star-studded sky. Among the villagers was a young dreamer named Elara, whose curiosity about the world beyond the mountains sparked tales of adventure and discovery. Little did she know, her destiny was intertwined with the very legends that danced in the shadows of Eldoria's enchanted night.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ['[CLS]', 'in', 'a', 'random', 'hidden', 'valley', 'surrounded', 'by', 'towering', 'mountains', ',', 'the', 'ancient', 'village', 'of', 'eld', 'oria', 'thrived', 'in', 'harmonious', 'isolation', '.', 'the', 'villagers', 'spoke', 'of', 'magical', 'creatures', 'dwelling', 'in', 'the', 'dense', 'forests', ',', 'guardians', 'of', 'secrets', 'lost', 'to', 'time', '.', 'each', 'spring', ',', 'a', 'festival', 'of', 'lights', 'transformed', 'the', 'village', 'into', 'a', 'realm', 'of', 'wonder', ',', 'with', 'lanterns', 'floating', 'like', 'ethereal', 'fire', 'flies', 'against', 'the', 'star', '-', 'studded', 'sky', '.', 'among', 'the', 'villagers', 'was', 'a', 'young', 'dreamer', 'named', 'el', 'ara', ',', 'whose', 'curiosity', 'about', 'the', 'world', 'beyond', 'the', 'mountains', 'sparked', 'tales', 'of', 'adventure', 'and', 'discovery', '.', 'little', 'did', 'she', 'know', ',', 'her', 'destiny', 'was', 'intertwined', 'with', 'the', 'very', 'legends', 'that', 'danced', 'in', 'the', 'shadows', 'of', 'eld', 'oria', \"'\", 's', 'enchanted', 'night', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sen_enc=tokenizer.encode(sen)\n",
    "print(f\"Output: {sen_enc.tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
